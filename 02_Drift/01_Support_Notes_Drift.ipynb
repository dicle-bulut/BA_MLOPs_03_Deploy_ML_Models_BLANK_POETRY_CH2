{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841411ac",
   "metadata": {},
   "source": [
    "<img src=\"media/LandingPage-Header-RED-CENTRE.jpg\" alt=\"Notebook Banner\" style=\"width:100%; height:auto; display:block; margin-left:auto; margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Data Drift, Concept Drift, and Outliers\n",
    "\n",
    "This section provides an overview of the theoretical concepts and methods used for detecting different types of drift and outliers in machine learning models, as demonstrated in the subsequent code sections.\n",
    "\n",
    "## Data Drift\n",
    "\n",
    "Refers to changes in the statistical properties of the input data used by a machine learning model over time. This can lead to a degradation in model performance, even if the underlying relationship between features and the target remains constant. We use statistical tests and distance metrics to compare the distributions of features between a reference dataset (e.g., training data) and a current production dataset.\n",
    "\n",
    "### Techniques to Measure Data Drift\n",
    "\n",
    "The following statistical tests and metrics are frequently used to quantify data drift. They are grouped by the type of variable each method best addresses.\n",
    "\n",
    "#### For Numerical Variables\n",
    "\n",
    "- **Population Stability Index (PSI)**  \n",
    "  Quantifies distributional differences between two data sets by binning the data and comparing percentage shares per bin. A high PSI indicates a material shift.\n",
    "\n",
    "- **Kolmogorov–Smirnov (KS) test**  \n",
    "  A non-parametric test that compares the cumulative distribution functions of two samples. Sensitive to changes in location, shape, or scale, and often a default choice for numerical features.\n",
    "\n",
    "- **Jensen–Shannon Divergence (JSD)**  \n",
    "  Measures similarity between two probability distributions, bounded between 0 and 1 for ease of interpretation. Higher values denote greater divergence.\n",
    "\n",
    "\n",
    "#### For Categorical Variables\n",
    "\n",
    "- **Chi-squared test**  \n",
    "  Compares observed category frequencies in the new data against expected frequencies from a baseline data set to detect significant differences.\n",
    "\n",
    "In the example that follows, we will explore the concept of data drift.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db845d5",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d95522a",
   "metadata": {},
   "source": [
    "# Introduction to Data Drift for *Heritage Brew Collective*\n",
    "\n",
    "Consider the case of a neighborhood coffee shop, *Heritage Brew Collective*. Over the prioryear, management collected customer level data to understand behavior and forecast loyalty or churn. That historical dataset serves as the **reference data** used to train a customer-prediction model.\n",
    "\n",
    "This year, the model is being applied to new, incoming observations designated as the **current data**.  The central question is whether the customer base has changed materially year over year. If meaningful differences exist, model performance may degrade due to **data drift**.\n",
    "\n",
    "## Feature Categories Under Review\n",
    "\n",
    "- **Numerical features** — for example, the average number of visits per month.  \n",
    "- **Categorical features** — for example, the preferred drink category (Coffee, Tea, Specialty).\n",
    "\n",
    "\n",
    "## Drift-Detection Metrics\n",
    "\n",
    "- **Population Stability Index (PSI)** for numerical variables.  \n",
    "- **Chi-squared test** for categorical variables.\n",
    "\n",
    "\n",
    "The following analysis determines whether the current customer population remains consistent with the historical baseline.\n",
    "\n",
    "### Scenario setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2f257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "279c485a",
   "metadata": {},
   "source": [
    "### Visual comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65beed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Visualizations to Compare Distributions ---\n",
    "\n",
    "# --- Numerical Features ---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6cb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Categorical Features ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9071ec",
   "metadata": {},
   "source": [
    "### Analysing drift \n",
    "#### Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Numerical Drift Detection: Population Stability Index (PSI) ---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Numerical Features ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915f4ee",
   "metadata": {},
   "source": [
    "#### Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88144833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Categorical Drift Detection: Chi-Squared Test ---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Categorical Features ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d198827",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "- **Average Visits Per Month (Numerical)** — The Population Stability Index (PSI) is **0.4402**, well above the 0.25 action threshold, indicating a meaningful shift toward **fewer** monthly visits in the current data. Potential drivers may include increased local competition or a greater prevalence of remote work.\n",
    "\n",
    "- **Favorite Drink Category (Categorical)** — The Chi-squared test produced a p-value of **0.0000**, far below the 0.05 significance level, confirming a statistically significant change in customer preferences. The categorical distribution shows a decline in **“Coffee”** orders and a rise in **“Specialty”** beverages. Menu positioning and promotional strategy should be adjusted accordingly.\n",
    "\n",
    "- **Age and Loyalty-Program Membership** — Both variables exhibit **no significant drift**, suggesting that the customer demographic profile and loyalty engagement remain stable.\n",
    "\n",
    "\n",
    "## Interpreting a “Global Drift Score” in Practice\n",
    "\n",
    "A single composite metric risks masking critical feature-level issues. e.g., If 99 features show no drift but 1 crucial feature has extreme drift, a simple average might make the overall score look fine—misleading us. Instead, a practical overview combines:\n",
    "\n",
    "1. **Feature-Level Drift Counts**  \n",
    "   Drift was identified in **2 of 4 monitored features**, immediately highlighting that half of the key variables have materially changed.\n",
    "\n",
    "2. **Impact on Model Performance**  \n",
    "   Ultimately, the most consequential indicator is the performance of downstream models (e.g., churn-prediction accuracy). Abrupt degradation is a clear signal that the detected drift is affecting business outcomes. Feature-level diagnostics (PSI, Chi-squared) help to isolate the contributing variables.\n",
    "\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "Significant drift is present in customer visit frequency and drink preferences, while age and loyalty metrics remain stable. Ongoing monitoring of the churn-prediction model is recommended, with consideration for retraining on the updated data—particularly to account for evolving drink-preference patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f76810",
   "metadata": {},
   "source": [
    "# Evidently AI for Automated Drift Diagnostics\n",
    "\n",
    "Earlier, we manually calculated the **Population Stability Index (PSI)** for numerical variables and the **Chi-squared test** for categorical variables. While this clarifies the underlying statistics, production workflows typically rely on specialised tooling for efficiency and reproducibility.\n",
    "\n",
    "**Evidently AI** is an open-source Python library that streamlines the drift-evaluation process by providing:\n",
    "\n",
    "- **Drift detection**: applies statistical tests (including PSI and Chi-squared) across selected features.  \n",
    "- **Visualisation**: produces interactive plots that highlight distributional changes.  \n",
    "- **Reporting**: compiles a comprehensive HTML report that can be viewed in-notebook or shared with stakeholders.\n",
    "\n",
    "https://docs.evidentlyai.com/introduction\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "To use Evidently AI, you'll need a Python environment with the library installed. If you haven't already, you can install it using pip:\n",
    "```bash\n",
    "\n",
    "pip install evidently\n",
    "```\n",
    "\n",
    "Evidently AI enables rapid, repeatable drift assessments with minimal code overhead.\n",
    "\n",
    "*Next, we shall integrate Evidently AI into our workflow and review its results.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 2. Map the schema\n",
    "# -------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b94f0",
   "metadata": {},
   "source": [
    "Evidently selects the statistical test automatically, and the choice depends on how many distinct values each column contains.\n",
    "\n",
    "| Column | Distinct categories (`n_unique`) | Default test Evidently applies | Reason |\n",
    "|--------|----------------------------------|--------------------------------|--------|\n",
    "| `Loyalty_Program_Member` | 2 (`Yes`, `No`) | Two-proportion z-test | When a feature is binary, Evidently compares two independent proportions and applies the z-test. |\n",
    "| `Favorite_Drink_Category` | 3 (`Coffee`, `Tea`, `Specialty`) | Chi-squared test | For multi-class categorical variables (`n_unique` greater than 2) Evidently runs the Pearson chi-squared test to compare the full distribution across classes. |\n",
    "\n",
    "The rule is part of Evidently’s default drift-detection logic for tabular data:\n",
    "\n",
    "- Binary categorical → proportion z-test  \n",
    "- Categorical with more than two levels → chi-squared test  \n",
    "- Numerical (or categorical with very few unique values) → other tests such as KS or Wasserstein, depending on sample size  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5339de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Report to an HTML file ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1679b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': [{'id': '15e89f895b482f9b84ba7274ed18a106',\n",
       "   'metric_id': 'DriftedColumnsCount(drift_share=0.5)',\n",
       "   'value': {'count': 2.0, 'share': 0.5}},\n",
       "  {'id': '23fa9953455b31fa1983292360fee686',\n",
       "   'metric_id': 'ValueDrift(column=Average_Visits_Per_Month)',\n",
       "   'value': 9.185171040635447e-122},\n",
       "  {'id': '8f5d1c60a32d6fc1bd54bc53af61d8e8',\n",
       "   'metric_id': 'ValueDrift(column=Age)',\n",
       "   'value': 0.24068202486600215},\n",
       "  {'id': 'a38739929e1f77c72ee0757c627b673c',\n",
       "   'metric_id': 'ValueDrift(column=Favorite_Drink_Category)',\n",
       "   'value': 3.529680030793938e-97},\n",
       "  {'id': 'ca1f379701267b53d00b5547c04ac4fa',\n",
       "   'metric_id': 'ValueDrift(column=Loyalty_Program_Member)',\n",
       "   'value': 0.6652439504716796}],\n",
       " 'tests': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing Report Results Programmatically (for interpretation) ---\n",
    "# You can also access the results of the report programmatically if needed.\n",
    "# This can be useful for automated alerting or further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb14057b",
   "metadata": {},
   "source": [
    "# Understanding Concept Drift in Predictive Models\n",
    "\n",
    "Having examined **data drift**, which concerns shifts in the characteristics of input data, we now turn to **concept drift**, an equally critical challenge for machine-learning models.\n",
    "\n",
    "Consider a predictive model in a retail context, such as a coffee shop, designed to forecast **customer churn** (the cessation of customer engagement).\n",
    "\n",
    "- **Data drift** occurs when the *distribution of input features* changes (for example, an overall reduction in average customer visits).  \n",
    "- **Concept drift** arises when the *underlying relationship* between the input features and the target variable (churn) changes. In this situation the concept that the model initially learned to recognise is no longer valid.\n",
    "\n",
    "**Concept drift** occurs when the underlying relationship between the input features and the target variable changes over time. This directly impacts the model's ability to make correct predictions, even if the input data distribution itself hasn't changed. Detecting concept drift primarily relies on monitoring the model's performance metrics on incoming data, ideally where ground truth labels are available.\n",
    "\n",
    "These metrics are derived from the **Confusion Matrix**, which summarises the performance of a classification model:\n",
    "* **True Positives (TP):** Correctly predicted positive instances.\n",
    "* **True Negatives (TN):** Correctly predicted negative instances.\n",
    "* **False Positives (FP):** Incorrectly predicted positive instances (Type I error).\n",
    "* **False Negatives (FN):** Incorrectly predicted negative instances (Type II error).\n",
    "\n",
    "##### 1. Accuracy\n",
    "\n",
    "* **Definition:** The proportion of total predictions that were correct. It measures how often the classifier is correct overall.\n",
    "* **Formula:**\n",
    "    $$\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}$$\n",
    "* **Relevance to Concept Drift:** A significant drop in accuracy on new data, compared to baseline, indicates the model's overall correctness has degraded, suggesting concept drift.\n",
    "\n",
    "##### 2. Precision\n",
    "\n",
    "* **Definition:** Of all the instances predicted as positive, what proportion were actually positive. Answers: \"When the model predicts positive, how often is it correct?\"\n",
    "* **Formula:**\n",
    "    $$\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$\n",
    "* **Relevance to Concept Drift:** A drop in precision suggests the model is making more false positive errors than before, which can be a symptom of concept drift, especially if the cost of false positives is high (e.g., incorrectly identifying a customer as churning and offering a costly retention incentive).\n",
    "\n",
    "##### 3. Recall (Sensitivity or True Positive Rate)\n",
    "\n",
    "* **Definition:** Of all the actual positive instances, what proportion did the model correctly identify. Answers: \"Of all the actual positive cases, how many did the model 'recall' or find?\"\n",
    "* **Formula:**\n",
    "    $$\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$\n",
    "* **Relevance to Concept Drift:** A drop in recall suggests the model is missing more actual positive cases (false negatives) than before. This is critical for churn prediction, as missing actual churners means missed opportunities for retention, strongly indicating concept drift.\n",
    "\n",
    "##### 4. F1-Score\n",
    "\n",
    "* **Definition:** The harmonic mean of Precision and Recall. It provides a single score that balances both precision and recall.\n",
    "* **Formula:**\n",
    "    $$\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "* **Relevance to Concept Drift:** A drop in F1-Score indicates a degradation in the model's ability to balance false positives and false negatives, making it a robust overall indicator of concept drift, especially in imbalanced datasets.\n",
    "\n",
    "In the example that follows, we will explore concept drift on the scenario for *Heritage Brew Collective*.\n",
    "\n",
    "## Shifting Loyalty Dynamics for *Heritage Brew Collective*\n",
    "\n",
    "Previously, the model may have established a clear concept: customers with high visit frequency (for example, more than 10 visits per month) **and** participation in a loyalty programme were reliably classified as **non-churners**.\n",
    "\n",
    "A fundamental change in market conditions could alter this relationship:\n",
    "\n",
    "- **Scenario**: A new, highly competitive establishment enters the market, offering innovative products and an enhanced customer experience. Even historically frequent visitors and loyalty members might now explore alternatives.\n",
    "\n",
    "In this evolving environment, a customer's high **`Average_Visits_Per_Month`** and **`Loyalty_Programme_Member`** status may no longer predict non-churn behaviour. The **relationship** between these features and **`Churn`** has changed. Consequently, a model trained on the previous concept of loyalty would begin to generate inaccurate predictions.\n",
    "\n",
    "This illustrates concept drift: the input data may appear stable, yet the underlying predictive rules have changed. Monitoring model performance is the primary means of detecting concept drift, but with an interpretable model such as logistic regression we can also observe how the **coefficients** (the learned relationships) themselves change, offering direct insight into the nature of the drift.\n",
    "\n",
    "The following analysis will simulate such a scenario, demonstrating the impact on a churn-prediction model and, crucially, the shift in its learned coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d03b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Reference Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>Loyalty_Program_Member</th>\n",
       "      <th>Age</th>\n",
       "      <th>Average_Visits_Per_Month</th>\n",
       "      <th>Spend_Per_Visit</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>64</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>29</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>33</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>41</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>36</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id Loyalty_Program_Member  Age  Average_Visits_Per_Month  \\\n",
       "0            0                    Yes   64                       8.0   \n",
       "1            1                     No   29                       9.7   \n",
       "2            2                     No   33                       8.2   \n",
       "3            3                    Yes   41                       7.8   \n",
       "4            4                    Yes   36                       9.8   \n",
       "\n",
       "   Spend_Per_Visit  Churn  \n",
       "0             5.13      0  \n",
       "1             3.79      0  \n",
       "2             3.75      0  \n",
       "3             5.78      0  \n",
       "4             5.63      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reference Churn Rate: 0.02\n",
      "\n",
      "--- Current Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>Loyalty_Program_Member</th>\n",
       "      <th>Age</th>\n",
       "      <th>Average_Visits_Per_Month</th>\n",
       "      <th>Spend_Per_Visit</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>23</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>39</td>\n",
       "      <td>13.6</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>31</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>20</td>\n",
       "      <td>9.8</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id Loyalty_Program_Member  Age  Average_Visits_Per_Month  \\\n",
       "0            0                    Yes   51                       4.8   \n",
       "1            1                     No   23                       1.5   \n",
       "2            2                     No   39                      13.6   \n",
       "3            3                    Yes   31                       2.1   \n",
       "4            4                    Yes   20                       9.8   \n",
       "\n",
       "   Spend_Per_Visit  Churn  \n",
       "0             7.71      0  \n",
       "1             1.42      1  \n",
       "2             3.62      0  \n",
       "3             2.40      0  \n",
       "4             4.11      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Churn Rate: 0.35\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249fa58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Preprocessing for Model Training ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Evaluate Model Performance \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342fee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Visualising Logistic Regression Coefficients ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Current Data (Expected Performance Drop due to Concept Drift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Visualize Performance Degradation (Concept Drift Indicator) ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Generate Predictions for Evidently AI ---\n",
    "\n",
    "# Get predictions and probabilities from the trained model for both datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4645b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b062de1",
   "metadata": {},
   "source": [
    "### Data Drift Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62984499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 2. Map the schema (mandatory in the new API)\n",
    "# -------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf77e36",
   "metadata": {},
   "source": [
    "## Take Away\n",
    "\n",
    "This analysis with Evidently AI has demonstrated a key aspect of **concept drift**. We trained a model on the *reference* data, where customer loyalty and visit frequency were strong predictors of churn. When the same model was applied to the *current* data—where that relationship had weakened—we observed a clear decline in performance metrics such as **accuracy** and **ROC AUC**.\n",
    "\n",
    "The visible degradation in model performance is a direct indicator of concept drift. The model’s learned *concept* of churn is no longer a good fit for present-day behaviour, making its predictions less reliable.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Having confirmed concept drift (via performance decline) and data drift (through your earlier analysis), you can consider the following actions:\n",
    "\n",
    "1. **Retrain the model**  \n",
    "   The most common remedy is to retrain using the current data so the model can learn the updated relationship between features and churn. Retraining periodically can help the model adapt to a continually shifting concept.\n",
    "\n",
    "2. **Explore a different model**  \n",
    "   An alternative architecture may be more robust to changes in the underlying concept. You could evaluate a more flexible algorithm, such as Gradient Boosting Machines or Neural Networks, to determine whether they maintain performance over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad714f",
   "metadata": {},
   "source": [
    "## Outlier\n",
    "\n",
    "An **outlier** is a data point that differs markedly from other observations in a data set. Outliers may arise for several reasons, including:\n",
    "\n",
    "- **Measurement errors**: mistakes made during data collection  \n",
    "- **Data-entry errors**: typographical errors when values are recorded  \n",
    "- **True anomalies**: rare yet legitimate observations that genuinely deviate from the general pattern  \n",
    "\n",
    "Outliers can significantly affect machine-learning models, particularly linear models such as logistic regression. They may distort learnt relationships and lead to poorer overall performance. Identifying and handling them appropriately is therefore crucial.\n",
    "\n",
    "### Main Methods to Detect Outliers\n",
    "\n",
    "Various techniques exist for detecting outliers. Below are two straightforward statistical approaches:\n",
    "\n",
    "1. **Z-score method**  \n",
    "   This measures how many standard deviations a data point lies from the mean. A common rule of thumb is to flag any point with a Z-score greater than 3 or less than -3 as an outlier.\n",
    "\n",
    "2. **Interquartile range (IQR) method**  \n",
    "   This defines outliers as values falling below the first quartile (Q1) or above the third quartile (Q3) by more than 1.5 × IQR. It is especially useful for data that are not normally distributed.\n",
    "\n",
    "\n",
    "In the example that follows, we will explor this concept by manually insert a few outliers, and then locate them using visualisations and the Z-score method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42779a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Visualize the Outliers ---\n",
    "# A box plot is an excellent tool for visualizing outliers in a single feature.\n",
    "# A scatter plot helps visualize outliers in the context of two features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for two features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Outlier Detection using the Z-score Method ---\n",
    "# This function now returns the indices of the outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be238116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Outliers Detected by Z-score Method ---\n",
      "Indices of detected outliers: [596, 284, 685, 551]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11301a1a",
   "metadata": {},
   "source": [
    "### Key Strategies for Handling Outliers\n",
    "\n",
    "1. **Removal**  \n",
    "   Delete clearly erroneous values (e.g., an age of 200). Suitable when the outlier stems from data-entry or measurement errors. Remove sparingly to avoid excessive data loss.\n",
    "\n",
    "2. **Imputation / Capping**  \n",
    "   Retain the record but limit its influence, for example by replacing values above the 99th percentile with the 99th-percentile value (Winsorisation) or by substituting the median. Use when the point is genuine yet its magnitude distorts the model.\n",
    "\n",
    "3. **Transformation**  \n",
    "   Apply a mathematical function—logarithm or square root compress extreme values. Ideal for naturally skewed distributions (e.g., income) where outliers are inherent.\n",
    "\n",
    "4. **Separate Modelling**  \n",
    "   Treat outliers as a distinct class when they represent events of interest, such as fraud or rare faults. Build a dedicated detection model rather than removing or altering these observations.\n",
    "\n",
    "There is no universal remedy; the optimal technique depends on the data characteristics and the business objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Outlier Detection using the Z-score Method ---\n",
    "# This function now returns the indices of the outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a4adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Outliers Detected by Z-score Method ---\n",
      "Indices of detected outliers: [596, 284, 685, 551]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dbeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Handling Outliers with Functions ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f022cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data after Outlier Removal ---\n",
      "Original number of rows: 1000\n",
      "New number of rows: 996\n",
      "\n",
      "--- Data after Outlier Capping (with Median) ---\n",
      "Original number of rows: 1000\n",
      "New number of rows: 1000\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the new functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Visualize the Outliers ---\n",
    "# A box plot is an excellent tool for visualizing outliers in a single feature.\n",
    "# A scatter plot helps visualize outliers in the context of two features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f5f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Visualize the Outliers ---\n",
    "# A box plot is an excellent tool for visualizing outliers in a single feature.\n",
    "# A scatter plot helps visualize outliers in the context of two features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da202578",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has shown how to identify and handle outliers. By visualising the data with box plots and scatter plots, we could clearly see those observations that lay far from the main cluster. The **z-score method** then provided a robust, statistical approach to detect the same outliers programmatically.\n",
    "\n",
    "We have also created functions to either **remove** the outliers entirely or **cap** them at a less extreme value (for example, the mean, median, or maximum of the non-outlier data). These options give you flexible ways to prepare your data.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "With tools in place to detect and handle outliers, here are two avenues to explore:\n",
    "\n",
    "1. **Evaluate the impact**  \n",
    "   Use the cleaned data (either the removed-outlier or capped-outlier version) to train the churn-prediction model and compare performance. This will reveal whether addressing outliers actually improves accuracy.\n",
    "\n",
    "2. **Compare handling methods**  \n",
    "   Train one model on data with removed outliers and another on data with capped outliers, then compare their performance. This helps determine which strategy is best for your specific dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568dba19",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
